{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas\n",
    "import pandas as pd\n",
    "\n",
    "# numpy, matplotlib, seaborn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# GridSearchCV to find optimal min_samples_split\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Importing train-test-split \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import *\n",
    "\n",
    "# Ignoring warning\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>department</th>\n",
       "      <th>region</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>recruitment_channel</th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won</th>\n",
       "      <th>avg_training_score</th>\n",
       "      <th>is_promoted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employee_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65438</th>\n",
       "      <td>SalesMarketing</td>\n",
       "      <td>region_7</td>\n",
       "      <td>Masters</td>\n",
       "      <td>f</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65141</th>\n",
       "      <td>Operations</td>\n",
       "      <td>region_22</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7513</th>\n",
       "      <td>SalesMarketing</td>\n",
       "      <td>region_19</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2542</th>\n",
       "      <td>SalesMarketing</td>\n",
       "      <td>region_23</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48945</th>\n",
       "      <td>Technology</td>\n",
       "      <td>region_26</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 department     region  education gender recruitment_channel  \\\n",
       "employee_id                                                                    \n",
       "65438        SalesMarketing   region_7    Masters      f            sourcing   \n",
       "65141            Operations  region_22  Bachelors      m               other   \n",
       "7513         SalesMarketing  region_19  Bachelors      m            sourcing   \n",
       "2542         SalesMarketing  region_23  Bachelors      m               other   \n",
       "48945            Technology  region_26  Bachelors      m               other   \n",
       "\n",
       "             no_of_trainings  age  previous_year_rating  length_of_service  \\\n",
       "employee_id                                                                  \n",
       "65438                      1   35                     5                  8   \n",
       "65141                      1   30                     5                  4   \n",
       "7513                       1   34                     3                  7   \n",
       "2542                       2   39                     1                 10   \n",
       "48945                      1   45                     3                  2   \n",
       "\n",
       "             KPIs_met >80%  awards_won  avg_training_score  is_promoted  \n",
       "employee_id                                                              \n",
       "65438                    1           0                  49            0  \n",
       "65141                    0           0                  60            0  \n",
       "7513                     0           0                  50            0  \n",
       "2542                     0           0                  50            0  \n",
       "48945                    0           0                  73            0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee = pd.read_csv('employee.csv',index_col=0)\n",
    "employee.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "department               9\n",
       "region                  34\n",
       "education                4\n",
       "gender                   2\n",
       "recruitment_channel      3\n",
       "no_of_trainings         10\n",
       "age                     41\n",
       "previous_year_rating     6\n",
       "length_of_service       35\n",
       "KPIs_met >80%            2\n",
       "awards_won               2\n",
       "avg_training_score      61\n",
       "is_promoted              2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 54808 entries, 65438 to 51526\n",
      "Data columns (total 13 columns):\n",
      "department              54808 non-null object\n",
      "region                  54808 non-null object\n",
      "education               54808 non-null object\n",
      "gender                  54808 non-null object\n",
      "recruitment_channel     54808 non-null object\n",
      "no_of_trainings         54808 non-null int64\n",
      "age                     54808 non-null int64\n",
      "previous_year_rating    54808 non-null int64\n",
      "length_of_service       54808 non-null int64\n",
      "KPIs_met >80%           54808 non-null int64\n",
      "awards_won              54808 non-null int64\n",
      "avg_training_score      54808 non-null int64\n",
      "is_promoted             54808 non-null int64\n",
      "dtypes: int64(8), object(5)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "employee.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns like `no_of_trainings, previous_year_rating , KPIs_met >80% , awards_won` are actualy categorical but given in the interger format ,so these columns need to be converted as objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting numerical data into categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_int_obj = ['no_of_trainings','previous_year_rating','KPIs_met >80%','awards_won']\n",
    "for col in list_int_obj:\n",
    "    employee[col] = employee[col].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 54808 entries, 65438 to 51526\n",
      "Data columns (total 13 columns):\n",
      "department              54808 non-null object\n",
      "region                  54808 non-null object\n",
      "education               54808 non-null object\n",
      "gender                  54808 non-null object\n",
      "recruitment_channel     54808 non-null object\n",
      "no_of_trainings         54808 non-null object\n",
      "age                     54808 non-null int64\n",
      "previous_year_rating    54808 non-null object\n",
      "length_of_service       54808 non-null int64\n",
      "KPIs_met >80%           54808 non-null object\n",
      "awards_won              54808 non-null object\n",
      "avg_training_score      54808 non-null int64\n",
      "is_promoted             54808 non-null int64\n",
      "dtypes: int64(4), object(9)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "employee.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Onehot encoding for categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54808, 67)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.get_dummies(employee,drop_first=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>avg_training_score</th>\n",
       "      <th>is_promoted</th>\n",
       "      <th>department_Finance</th>\n",
       "      <th>department_HR</th>\n",
       "      <th>department_Legal</th>\n",
       "      <th>department_Operations</th>\n",
       "      <th>department_Procurement</th>\n",
       "      <th>department_RandD</th>\n",
       "      <th>...</th>\n",
       "      <th>no_of_trainings_7</th>\n",
       "      <th>no_of_trainings_8</th>\n",
       "      <th>no_of_trainings_9</th>\n",
       "      <th>previous_year_rating_1</th>\n",
       "      <th>previous_year_rating_2</th>\n",
       "      <th>previous_year_rating_3</th>\n",
       "      <th>previous_year_rating_4</th>\n",
       "      <th>previous_year_rating_5</th>\n",
       "      <th>KPIs_met &gt;80%_1</th>\n",
       "      <th>awards_won_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employee_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65438</th>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65141</th>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7513</th>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2542</th>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48945</th>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             age  length_of_service  avg_training_score  is_promoted  \\\n",
       "employee_id                                                            \n",
       "65438         35                  8                  49            0   \n",
       "65141         30                  4                  60            0   \n",
       "7513          34                  7                  50            0   \n",
       "2542          39                 10                  50            0   \n",
       "48945         45                  2                  73            0   \n",
       "\n",
       "             department_Finance  department_HR  department_Legal  \\\n",
       "employee_id                                                        \n",
       "65438                         0              0                 0   \n",
       "65141                         0              0                 0   \n",
       "7513                          0              0                 0   \n",
       "2542                          0              0                 0   \n",
       "48945                         0              0                 0   \n",
       "\n",
       "             department_Operations  department_Procurement  department_RandD  \\\n",
       "employee_id                                                                    \n",
       "65438                            0                       0                 0   \n",
       "65141                            1                       0                 0   \n",
       "7513                             0                       0                 0   \n",
       "2542                             0                       0                 0   \n",
       "48945                            0                       0                 0   \n",
       "\n",
       "                 ...       no_of_trainings_7  no_of_trainings_8  \\\n",
       "employee_id      ...                                              \n",
       "65438            ...                       0                  0   \n",
       "65141            ...                       0                  0   \n",
       "7513             ...                       0                  0   \n",
       "2542             ...                       0                  0   \n",
       "48945            ...                       0                  0   \n",
       "\n",
       "             no_of_trainings_9  previous_year_rating_1  \\\n",
       "employee_id                                              \n",
       "65438                        0                       0   \n",
       "65141                        0                       0   \n",
       "7513                         0                       0   \n",
       "2542                         0                       1   \n",
       "48945                        0                       0   \n",
       "\n",
       "             previous_year_rating_2  previous_year_rating_3  \\\n",
       "employee_id                                                   \n",
       "65438                             0                       0   \n",
       "65141                             0                       0   \n",
       "7513                              0                       1   \n",
       "2542                              0                       0   \n",
       "48945                             0                       1   \n",
       "\n",
       "             previous_year_rating_4  previous_year_rating_5  KPIs_met >80%_1  \\\n",
       "employee_id                                                                    \n",
       "65438                             0                       1                1   \n",
       "65141                             0                       1                0   \n",
       "7513                              0                       0                0   \n",
       "2542                              0                       0                0   \n",
       "48945                             0                       0                0   \n",
       "\n",
       "             awards_won_1  \n",
       "employee_id                \n",
       "65438                   0  \n",
       "65141                   0  \n",
       "7513                    0  \n",
       "2542                    0  \n",
       "48945                   0  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[['age','length_of_service','avg_training_score']]\n",
    "transformed_data = (df-df.mean())/df.std()\n",
    "data = data.drop(['age','length_of_service','avg_training_score'],1)\n",
    "data = pd.concat([data,transformed_data],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_promoted</th>\n",
       "      <th>department_Finance</th>\n",
       "      <th>department_HR</th>\n",
       "      <th>department_Legal</th>\n",
       "      <th>department_Operations</th>\n",
       "      <th>department_Procurement</th>\n",
       "      <th>department_RandD</th>\n",
       "      <th>department_SalesMarketing</th>\n",
       "      <th>department_Technology</th>\n",
       "      <th>region_region_10</th>\n",
       "      <th>...</th>\n",
       "      <th>previous_year_rating_1</th>\n",
       "      <th>previous_year_rating_2</th>\n",
       "      <th>previous_year_rating_3</th>\n",
       "      <th>previous_year_rating_4</th>\n",
       "      <th>previous_year_rating_5</th>\n",
       "      <th>KPIs_met &gt;80%_1</th>\n",
       "      <th>awards_won_1</th>\n",
       "      <th>age</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>avg_training_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employee_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65438</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025598</td>\n",
       "      <td>0.500455</td>\n",
       "      <td>-1.075922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65141</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.627129</td>\n",
       "      <td>-0.437391</td>\n",
       "      <td>-0.253280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7513</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.104947</td>\n",
       "      <td>0.265994</td>\n",
       "      <td>-1.001136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2542</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.547780</td>\n",
       "      <td>0.969378</td>\n",
       "      <td>-1.001136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48945</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.331052</td>\n",
       "      <td>-0.906313</td>\n",
       "      <td>0.718933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             is_promoted  department_Finance  department_HR  department_Legal  \\\n",
       "employee_id                                                                     \n",
       "65438                  0                   0              0                 0   \n",
       "65141                  0                   0              0                 0   \n",
       "7513                   0                   0              0                 0   \n",
       "2542                   0                   0              0                 0   \n",
       "48945                  0                   0              0                 0   \n",
       "\n",
       "             department_Operations  department_Procurement  department_RandD  \\\n",
       "employee_id                                                                    \n",
       "65438                            0                       0                 0   \n",
       "65141                            1                       0                 0   \n",
       "7513                             0                       0                 0   \n",
       "2542                             0                       0                 0   \n",
       "48945                            0                       0                 0   \n",
       "\n",
       "             department_SalesMarketing  department_Technology  \\\n",
       "employee_id                                                     \n",
       "65438                                1                      0   \n",
       "65141                                0                      0   \n",
       "7513                                 1                      0   \n",
       "2542                                 1                      0   \n",
       "48945                                0                      1   \n",
       "\n",
       "             region_region_10         ...          previous_year_rating_1  \\\n",
       "employee_id                           ...                                   \n",
       "65438                       0         ...                               0   \n",
       "65141                       0         ...                               0   \n",
       "7513                        0         ...                               0   \n",
       "2542                        0         ...                               1   \n",
       "48945                       0         ...                               0   \n",
       "\n",
       "             previous_year_rating_2  previous_year_rating_3  \\\n",
       "employee_id                                                   \n",
       "65438                             0                       0   \n",
       "65141                             0                       0   \n",
       "7513                              0                       1   \n",
       "2542                              0                       0   \n",
       "48945                             0                       1   \n",
       "\n",
       "             previous_year_rating_4  previous_year_rating_5  KPIs_met >80%_1  \\\n",
       "employee_id                                                                    \n",
       "65438                             0                       1                1   \n",
       "65141                             0                       1                0   \n",
       "7513                              0                       0                0   \n",
       "2542                              0                       0                0   \n",
       "48945                             0                       0                0   \n",
       "\n",
       "             awards_won_1       age  length_of_service  avg_training_score  \n",
       "employee_id                                                                 \n",
       "65438                   0  0.025598           0.500455           -1.075922  \n",
       "65141                   0 -0.627129          -0.437391           -0.253280  \n",
       "7513                    0 -0.104947           0.265994           -1.001136  \n",
       "2542                    0  0.547780           0.969378           -1.001136  \n",
       "48945                   0  1.331052          -0.906313            0.718933  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating X-variables and Y-variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = data.drop('is_promoted',1)\n",
    "y_data = data['is_promoted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(clf,X_train,Y_train):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.20, stratify = Y_train, random_state = 99)\n",
    "    clf.fit(x_train,y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print('Scores of the Model')\n",
    "    print('Confusion Matrix of the model:')\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print('-----------------------------------------')\n",
    "    print('Accuracy Score:',accuracy_score(y_test,y_pred))\n",
    "    print('-----------------------------------------')\n",
    "    print('Classification report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('------------------------------------------')\n",
    "    print('f1 score:',f1_score(y_test,y_pred))\n",
    "    print('------------------------------------------')\n",
    "    print('ROC AUC score:',roc_auc_score(y_test,y_pred))\n",
    "    print('------------------------------------------')\n",
    "    print('')\n",
    "    print('Cross Validation using KFold:')\n",
    "    kf = KFold(n_splits=5,random_state=99)\n",
    "    print('Accuracy score using KFold cross validation:')\n",
    "    score = cross_val_score(clf, X_train, Y_train, cv=kf,scoring='f1', n_jobs=1)\n",
    "    for i in score:\n",
    "        print('cross_val_score:',i)\n",
    "    print('Mean Acuuracy Score:',score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2(model):\n",
    "    return 1-(model.deviance/model.null_deviance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores of the Model\n",
      "Confusion Matrix of the model:\n",
      "[[9977   51]\n",
      " [ 712  222]]\n",
      "-----------------------------------------\n",
      "Accuracy Score: 0.9303959131545338\n",
      "-----------------------------------------\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     10028\n",
      "           1       0.81      0.24      0.37       934\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10962\n",
      "   macro avg       0.87      0.62      0.67     10962\n",
      "weighted avg       0.92      0.93      0.91     10962\n",
      "\n",
      "------------------------------------------\n",
      "f1 score: 0.36785418392709196\n",
      "------------------------------------------\n",
      "ROC AUC score: 0.6163008031473332\n",
      "------------------------------------------\n",
      "\n",
      "Cross Validation using KFold:\n",
      "Accuracy score using KFold cross validation:\n",
      "cross_val_score: 0.3829113924050633\n",
      "cross_val_score: 0.37795275590551186\n",
      "cross_val_score: 0.37437603993344426\n",
      "cross_val_score: 0.380178716490658\n",
      "cross_val_score: 0.3648315529991783\n",
      "Mean Acuuracy Score: 0.37605009154677116\n"
     ]
    }
   ],
   "source": [
    "model(LogisticRegression(),x_data,y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=10000, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "0.4072066326530612\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4,10**6]}]\n",
    "\n",
    "model_lr = GridSearchCV(LogisticRegression(), tuned_parameters, scoring = 'f1', cv=5)\n",
    "model_lr.fit(x_data, y_data)\n",
    "\n",
    "print(model_lr.best_estimator_)\n",
    "print(model_lr.score(x_data, y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores of the Model\n",
      "Confusion Matrix of the model:\n",
      "[[9958   70]\n",
      " [ 689  245]]\n",
      "-----------------------------------------\n",
      "Accuracy Score: 0.9307608100711549\n",
      "-----------------------------------------\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96     10028\n",
      "           1       0.78      0.26      0.39       934\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10962\n",
      "   macro avg       0.86      0.63      0.68     10962\n",
      "weighted avg       0.92      0.93      0.91     10962\n",
      "\n",
      "------------------------------------------\n",
      "f1 score: 0.3923138510808647\n",
      "------------------------------------------\n",
      "ROC AUC score: 0.6276660895531058\n",
      "------------------------------------------\n",
      "\n",
      "Cross Validation using KFold:\n",
      "Accuracy score using KFold cross validation:\n",
      "cross_val_score: 0.40853658536585363\n",
      "cross_val_score: 0.4003392705682782\n",
      "cross_val_score: 0.40927258193445243\n",
      "cross_val_score: 0.41809672386895474\n",
      "cross_val_score: 0.39171974522292996\n",
      "Mean Acuuracy Score: 0.4055929813920939\n"
     ]
    }
   ],
   "source": [
    "lr= LogisticRegression(C=10000, penalty='l2')\n",
    "model(lr,x_data,y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model using decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores of the Model\n",
      "Confusion Matrix of the model:\n",
      "[[9376  652]\n",
      " [ 498  436]]\n",
      "-----------------------------------------\n",
      "Accuracy Score: 0.8950921364714468\n",
      "-----------------------------------------\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     10028\n",
      "           1       0.40      0.47      0.43       934\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     10962\n",
      "   macro avg       0.68      0.70      0.69     10962\n",
      "weighted avg       0.90      0.90      0.90     10962\n",
      "\n",
      "------------------------------------------\n",
      "f1 score: 0.4312561819980218\n",
      "------------------------------------------\n",
      "ROC AUC score: 0.7008957360504079\n",
      "------------------------------------------\n",
      "\n",
      "Cross Validation using KFold:\n",
      "Accuracy score using KFold cross validation:\n",
      "cross_val_score: 0.43640020110608346\n",
      "cross_val_score: 0.4264550264550265\n",
      "cross_val_score: 0.42176165803108806\n",
      "cross_val_score: 0.4600197433366239\n",
      "cross_val_score: 0.42021010505252626\n",
      "Mean Acuuracy Score: 0.4329693467962696\n"
     ]
    }
   ],
   "source": [
    "model(DecisionTreeClassifier(),x_data,y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores of the Model\n",
      "Confusion Matrix of the model:\n",
      "[[9948   80]\n",
      " [ 716  218]]\n",
      "-----------------------------------------\n",
      "Accuracy Score: 0.9273855135924102\n",
      "-----------------------------------------\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     10028\n",
      "           1       0.73      0.23      0.35       934\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10962\n",
      "   macro avg       0.83      0.61      0.66     10962\n",
      "weighted avg       0.92      0.93      0.91     10962\n",
      "\n",
      "------------------------------------------\n",
      "f1 score: 0.35389610389610393\n",
      "------------------------------------------\n",
      "ROC AUC score: 0.6127135241879483\n",
      "------------------------------------------\n",
      "\n",
      "Cross Validation using KFold:\n",
      "Accuracy score using KFold cross validation:\n",
      "cross_val_score: 0.3853769992383854\n",
      "cross_val_score: 0.370739817123857\n",
      "cross_val_score: 0.38560000000000005\n",
      "cross_val_score: 0.3736263736263736\n",
      "cross_val_score: 0.3944099378881987\n",
      "Mean Acuuracy Score: 0.38195062557536297\n"
     ]
    }
   ],
   "source": [
    "model(RandomForestClassifier(),x_data,y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['is_promoted', 'department_Finance', 'department_HR',\n",
       "       'department_Legal', 'department_Operations', 'department_Procurement',\n",
       "       'department_RandD', 'department_SalesMarketing',\n",
       "       'department_Technology', 'region_region_10', 'region_region_11',\n",
       "       'region_region_12', 'region_region_13', 'region_region_14',\n",
       "       'region_region_15', 'region_region_16', 'region_region_17',\n",
       "       'region_region_18', 'region_region_19', 'region_region_2',\n",
       "       'region_region_20', 'region_region_21', 'region_region_22',\n",
       "       'region_region_23', 'region_region_24', 'region_region_25',\n",
       "       'region_region_26', 'region_region_27', 'region_region_28',\n",
       "       'region_region_29', 'region_region_3', 'region_region_30',\n",
       "       'region_region_31', 'region_region_32', 'region_region_33',\n",
       "       'region_region_34', 'region_region_4', 'region_region_5',\n",
       "       'region_region_6', 'region_region_7', 'region_region_8',\n",
       "       'region_region_9', 'education_BelowSecondary', 'education_Masters',\n",
       "       'education_NotSpecified', 'gender_m', 'recruitment_channel_referred',\n",
       "       'recruitment_channel_sourcing', 'no_of_trainings_10',\n",
       "       'no_of_trainings_2', 'no_of_trainings_3', 'no_of_trainings_4',\n",
       "       'no_of_trainings_5', 'no_of_trainings_6', 'no_of_trainings_7',\n",
       "       'no_of_trainings_8', 'no_of_trainings_9', 'previous_year_rating_1',\n",
       "       'previous_year_rating_2', 'previous_year_rating_3',\n",
       "       'previous_year_rating_4', 'previous_year_rating_5', 'KPIs_met >80%_1',\n",
       "       'awards_won_1', 'age', 'length_of_service', 'avg_training_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "logm1 = sm.GLM(y_data,(sm.add_constant(x_data)), family = sm.families.Binomial())\n",
    "model1 = logm1.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33111376922178914"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>               <td>GLM</td>            <td>AIC:</td>        <td>21486.3099</td> \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>Link Function:</td>          <td>logit</td>           <td>BIC:</td>       <td>-575959.1175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>    <td>is_promoted</td>   <td>Log-Likelihood:</td>    <td>-10676.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2019-04-07 12:50</td>    <td>LL-Null:</td>        <td>-15961.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>54808</td>         <td>Deviance:</td>       <td>21352.</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>66</td>         <td>Pearson chi2:</td>    <td>4.40e+04</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>54741</td>          <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "        <td>Method:</td>             <td>IRLS</td>              <td></td>               <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                 <th>Coef.</th>   <th>Std.Err.</th>      <th>z</th>     <th>P>|z|</th>   <th>[0.025</th>      <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                        <td>-10.4052</td>   <td>0.2344</td>   <td>-44.3970</td> <td>0.0000</td>  <td>-10.8646</td>     <td>-9.9459</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Finance</th>            <td>7.0614</td>    <td>0.1604</td>    <td>44.0367</td> <td>0.0000</td>   <td>6.7471</td>      <td>7.3757</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_HR</th>                 <td>9.9529</td>    <td>0.2117</td>    <td>47.0164</td> <td>0.0000</td>   <td>9.5380</td>      <td>10.3678</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Legal</th>              <td>6.8573</td>    <td>0.2126</td>    <td>32.2473</td> <td>0.0000</td>   <td>6.4405</td>      <td>7.2740</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Operations</th>         <td>7.2777</td>    <td>0.1417</td>    <td>51.3680</td> <td>0.0000</td>   <td>7.0000</td>      <td>7.5553</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Procurement</th>        <td>4.4102</td>    <td>0.1058</td>    <td>41.6783</td> <td>0.0000</td>   <td>4.2028</td>      <td>4.6176</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_RandD</th>              <td>-0.5515</td>   <td>0.1478</td>    <td>-3.7325</td> <td>0.0002</td>   <td>-0.8411</td>     <td>-0.2619</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_SalesMarketing</th>     <td>10.4652</td>   <td>0.1883</td>    <td>55.5865</td> <td>0.0000</td>   <td>10.0962</td>     <td>10.8342</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Technology</th>         <td>1.7745</td>    <td>0.0766</td>    <td>23.1719</td> <td>0.0000</td>   <td>1.6244</td>      <td>1.9246</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_10</th>              <td>0.1519</td>    <td>0.2388</td>    <td>0.6362</td>  <td>0.5247</td>   <td>-0.3161</td>     <td>0.6200</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_11</th>              <td>-0.3142</td>   <td>0.2168</td>    <td>-1.4490</td> <td>0.1473</td>   <td>-0.7392</td>     <td>0.1108</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_12</th>              <td>-0.4122</td>   <td>0.2888</td>    <td>-1.4274</td> <td>0.1535</td>   <td>-0.9782</td>     <td>0.1538</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_13</th>              <td>0.0583</td>    <td>0.1872</td>    <td>0.3116</td>  <td>0.7553</td>   <td>-0.3086</td>     <td>0.4253</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_14</th>              <td>0.0209</td>    <td>0.2248</td>    <td>0.0928</td>  <td>0.9260</td>   <td>-0.4197</td>     <td>0.4615</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_15</th>              <td>0.0851</td>    <td>0.1875</td>    <td>0.4537</td>  <td>0.6501</td>   <td>-0.2825</td>     <td>0.4527</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_16</th>              <td>-0.1001</td>   <td>0.2073</td>    <td>-0.4827</td> <td>0.6293</td>   <td>-0.5065</td>     <td>0.3063</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_17</th>              <td>0.5297</td>    <td>0.2114</td>    <td>2.5055</td>  <td>0.0122</td>   <td>0.1153</td>      <td>0.9441</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_18</th>              <td>0.2885</td>    <td>1.0598</td>    <td>0.2723</td>  <td>0.7854</td>   <td>-1.7886</td>     <td>2.3656</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_19</th>              <td>-0.0378</td>   <td>0.2336</td>    <td>-0.1616</td> <td>0.8716</td>   <td>-0.4955</td>     <td>0.4200</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_2</th>               <td>0.1718</td>    <td>0.1737</td>    <td>0.9888</td>  <td>0.3228</td>   <td>-0.1687</td>     <td>0.5122</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_20</th>              <td>-0.3751</td>   <td>0.2418</td>    <td>-1.5514</td> <td>0.1208</td>   <td>-0.8490</td>     <td>0.0988</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_21</th>              <td>-0.3841</td>   <td>0.3127</td>    <td>-1.2281</td> <td>0.2194</td>   <td>-0.9970</td>     <td>0.2289</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_22</th>              <td>0.4771</td>    <td>0.1743</td>    <td>2.7374</td>  <td>0.0062</td>   <td>0.1355</td>      <td>0.8187</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_23</th>              <td>0.4496</td>    <td>0.1997</td>    <td>2.2509</td>  <td>0.0244</td>   <td>0.0581</td>      <td>0.8410</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_24</th>              <td>-0.3265</td>   <td>0.3088</td>    <td>-1.0573</td> <td>0.2904</td>   <td>-0.9319</td>     <td>0.2788</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_25</th>              <td>0.5253</td>    <td>0.2086</td>    <td>2.5178</td>  <td>0.0118</td>   <td>0.1164</td>      <td>0.9342</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_26</th>              <td>-0.1089</td>   <td>0.1947</td>    <td>-0.5592</td> <td>0.5760</td>   <td>-0.4904</td>     <td>0.2727</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_27</th>              <td>0.1033</td>    <td>0.1994</td>    <td>0.5178</td>  <td>0.6046</td>   <td>-0.2876</td>     <td>0.4941</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_28</th>              <td>0.3700</td>    <td>0.1967</td>    <td>1.8815</td>  <td>0.0599</td>   <td>-0.0154</td>     <td>0.7555</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_29</th>              <td>-0.4746</td>   <td>0.2409</td>    <td>-1.9700</td> <td>0.0488</td>   <td>-0.9467</td>     <td>-0.0024</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_3</th>               <td>0.2860</td>    <td>0.2733</td>    <td>1.0465</td>  <td>0.2953</td>   <td>-0.2497</td>     <td>0.8217</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_30</th>              <td>0.1512</td>    <td>0.2395</td>    <td>0.6311</td>  <td>0.5280</td>   <td>-0.3183</td>     <td>0.6206</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_31</th>              <td>-0.2304</td>   <td>0.2030</td>    <td>-1.1351</td> <td>0.2563</td>   <td>-0.6282</td>     <td>0.1674</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_32</th>              <td>-0.4985</td>   <td>0.2495</td>    <td>-1.9978</td> <td>0.0457</td>   <td>-0.9876</td>     <td>-0.0094</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_33</th>              <td>-0.4052</td>   <td>0.3820</td>    <td>-1.0607</td> <td>0.2888</td>   <td>-1.1539</td>     <td>0.3435</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_34</th>              <td>-0.9665</td>   <td>0.4579</td>    <td>-2.1107</td> <td>0.0348</td>   <td>-1.8639</td>     <td>-0.0690</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_4</th>               <td>0.6563</td>    <td>0.1867</td>    <td>3.5163</td>  <td>0.0004</td>   <td>0.2905</td>      <td>1.0222</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_5</th>               <td>-0.3840</td>   <td>0.2619</td>    <td>-1.4660</td> <td>0.1426</td>   <td>-0.8973</td>     <td>0.1294</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_6</th>               <td>-0.4842</td>   <td>0.2683</td>    <td>-1.8045</td> <td>0.0712</td>   <td>-1.0101</td>     <td>0.0417</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_7</th>               <td>0.4076</td>    <td>0.1767</td>    <td>2.3068</td>  <td>0.0211</td>   <td>0.0613</td>      <td>0.7539</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_8</th>               <td>-0.1974</td>   <td>0.2409</td>    <td>-0.8194</td> <td>0.4126</td>   <td>-0.6696</td>     <td>0.2748</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_9</th>               <td>-1.1565</td>   <td>0.4304</td>    <td>-2.6869</td> <td>0.0072</td>   <td>-2.0000</td>     <td>-0.3129</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>education_BelowSecondary</th>      <td>-0.2308</td>   <td>0.1548</td>    <td>-1.4904</td> <td>0.1361</td>   <td>-0.5342</td>     <td>0.0727</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>education_Masters</th>             <td>0.1710</td>    <td>0.0452</td>    <td>3.7848</td>  <td>0.0002</td>   <td>0.0824</td>      <td>0.2595</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>education_NotSpecified</th>        <td>-0.4681</td>   <td>0.1148</td>    <td>-4.0796</td> <td>0.0000</td>   <td>-0.6930</td>     <td>-0.2432</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender_m</th>                      <td>0.0335</td>    <td>0.0419</td>    <td>0.7999</td>  <td>0.4238</td>   <td>-0.0486</td>     <td>0.1157</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recruitment_channel_referred</th>  <td>-0.2175</td>   <td>0.1135</td>    <td>-1.9161</td> <td>0.0554</td>   <td>-0.4399</td>     <td>0.0050</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recruitment_channel_sourcing</th>  <td>-0.0146</td>   <td>0.0375</td>    <td>-0.3884</td> <td>0.6978</td>   <td>-0.0880</td>     <td>0.0589</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>no_of_trainings_10</th>           <td>-19.3079</td> <td>34257.2130</td>  <td>-0.0006</td> <td>0.9996</td> <td>-67162.2115</td> <td>67123.5958</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>no_of_trainings_2</th>             <td>-0.1735</td>   <td>0.0547</td>    <td>-3.1703</td> <td>0.0015</td>   <td>-0.2808</td>     <td>-0.0662</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>no_of_trainings_3</th>             <td>-0.2499</td>   <td>0.1144</td>    <td>-2.1849</td> <td>0.0289</td>   <td>-0.4740</td>     <td>-0.0257</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>no_of_trainings_4</th>             <td>-0.4505</td>   <td>0.2385</td>    <td>-1.8892</td> <td>0.0589</td>   <td>-0.9180</td>     <td>0.0169</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>no_of_trainings_5</th>             <td>-0.7357</td>   <td>0.6226</td>    <td>-1.1817</td> <td>0.2373</td>   <td>-1.9560</td>     <td>0.4846</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>no_of_trainings_6</th>             <td>-0.1800</td>   <td>0.7552</td>    <td>-0.2384</td> <td>0.8116</td>   <td>-1.6602</td>     <td>1.3002</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>no_of_trainings_7</th>            <td>-20.8381</td> <td>20250.2288</td>  <td>-0.0010</td> <td>0.9992</td> <td>-39710.5572</td> <td>39668.8810</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>no_of_trainings_8</th>            <td>-20.5081</td> <td>33101.9511</td>  <td>-0.0006</td> <td>0.9995</td> <td>-64899.1399</td> <td>64858.1238</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>no_of_trainings_9</th>            <td>-20.8730</td> <td>34065.7905</td>  <td>-0.0006</td> <td>0.9995</td> <td>-66788.5955</td> <td>66746.8495</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>previous_year_rating_1</th>        <td>-1.4360</td>   <td>0.1409</td>   <td>-10.1929</td> <td>0.0000</td>   <td>-1.7121</td>     <td>-1.1598</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>previous_year_rating_2</th>        <td>-0.3751</td>   <td>0.1123</td>    <td>-3.3412</td> <td>0.0008</td>   <td>-0.5952</td>     <td>-0.1551</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>previous_year_rating_3</th>        <td>0.0137</td>    <td>0.0794</td>    <td>0.1731</td>  <td>0.8626</td>   <td>-0.1420</td>     <td>0.1694</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>previous_year_rating_4</th>        <td>-0.2909</td>   <td>0.0850</td>    <td>-3.4227</td> <td>0.0006</td>   <td>-0.4575</td>     <td>-0.1243</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>previous_year_rating_5</th>        <td>0.3264</td>    <td>0.0789</td>    <td>4.1385</td>  <td>0.0000</td>   <td>0.1718</td>      <td>0.4810</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>KPIs_met >80%_1</th>               <td>1.8802</td>    <td>0.0445</td>    <td>42.2391</td> <td>0.0000</td>   <td>1.7930</td>      <td>1.9674</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>awards_won_1</th>                  <td>1.5055</td>    <td>0.0799</td>    <td>18.8525</td> <td>0.0000</td>   <td>1.3490</td>      <td>1.6620</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                           <td>-0.2402</td>   <td>0.0288</td>    <td>-8.3500</td> <td>0.0000</td>   <td>-0.2966</td>     <td>-0.1838</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>length_of_service</th>             <td>0.1327</td>    <td>0.0260</td>    <td>5.1134</td>  <td>0.0000</td>   <td>0.0819</td>      <td>0.1836</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_training_score</th>            <td>4.0956</td>    <td>0.0687</td>    <td>59.5864</td> <td>0.0000</td>   <td>3.9609</td>      <td>4.2303</td>  \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                           Results: Generalized linear model\n",
       "=======================================================================================\n",
       "Model:                      GLM                     AIC:                   21486.3099  \n",
       "Link Function:              logit                   BIC:                   -575959.1175\n",
       "Dependent Variable:         is_promoted             Log-Likelihood:        -10676.     \n",
       "Date:                       2019-04-07 12:50        LL-Null:               -15961.     \n",
       "No. Observations:           54808                   Deviance:              21352.      \n",
       "Df Model:                   66                      Pearson chi2:          4.40e+04    \n",
       "Df Residuals:               54741                   Scale:                 1.0000      \n",
       "Method:                     IRLS                                                       \n",
       "---------------------------------------------------------------------------------------\n",
       "                              Coef.    Std.Err.     z     P>|z|     [0.025     0.975]  \n",
       "---------------------------------------------------------------------------------------\n",
       "const                        -10.4052     0.2344 -44.3970 0.0000    -10.8646    -9.9459\n",
       "department_Finance             7.0614     0.1604  44.0367 0.0000      6.7471     7.3757\n",
       "department_HR                  9.9529     0.2117  47.0164 0.0000      9.5380    10.3678\n",
       "department_Legal               6.8573     0.2126  32.2473 0.0000      6.4405     7.2740\n",
       "department_Operations          7.2777     0.1417  51.3680 0.0000      7.0000     7.5553\n",
       "department_Procurement         4.4102     0.1058  41.6783 0.0000      4.2028     4.6176\n",
       "department_RandD              -0.5515     0.1478  -3.7325 0.0002     -0.8411    -0.2619\n",
       "department_SalesMarketing     10.4652     0.1883  55.5865 0.0000     10.0962    10.8342\n",
       "department_Technology          1.7745     0.0766  23.1719 0.0000      1.6244     1.9246\n",
       "region_region_10               0.1519     0.2388   0.6362 0.5247     -0.3161     0.6200\n",
       "region_region_11              -0.3142     0.2168  -1.4490 0.1473     -0.7392     0.1108\n",
       "region_region_12              -0.4122     0.2888  -1.4274 0.1535     -0.9782     0.1538\n",
       "region_region_13               0.0583     0.1872   0.3116 0.7553     -0.3086     0.4253\n",
       "region_region_14               0.0209     0.2248   0.0928 0.9260     -0.4197     0.4615\n",
       "region_region_15               0.0851     0.1875   0.4537 0.6501     -0.2825     0.4527\n",
       "region_region_16              -0.1001     0.2073  -0.4827 0.6293     -0.5065     0.3063\n",
       "region_region_17               0.5297     0.2114   2.5055 0.0122      0.1153     0.9441\n",
       "region_region_18               0.2885     1.0598   0.2723 0.7854     -1.7886     2.3656\n",
       "region_region_19              -0.0378     0.2336  -0.1616 0.8716     -0.4955     0.4200\n",
       "region_region_2                0.1718     0.1737   0.9888 0.3228     -0.1687     0.5122\n",
       "region_region_20              -0.3751     0.2418  -1.5514 0.1208     -0.8490     0.0988\n",
       "region_region_21              -0.3841     0.3127  -1.2281 0.2194     -0.9970     0.2289\n",
       "region_region_22               0.4771     0.1743   2.7374 0.0062      0.1355     0.8187\n",
       "region_region_23               0.4496     0.1997   2.2509 0.0244      0.0581     0.8410\n",
       "region_region_24              -0.3265     0.3088  -1.0573 0.2904     -0.9319     0.2788\n",
       "region_region_25               0.5253     0.2086   2.5178 0.0118      0.1164     0.9342\n",
       "region_region_26              -0.1089     0.1947  -0.5592 0.5760     -0.4904     0.2727\n",
       "region_region_27               0.1033     0.1994   0.5178 0.6046     -0.2876     0.4941\n",
       "region_region_28               0.3700     0.1967   1.8815 0.0599     -0.0154     0.7555\n",
       "region_region_29              -0.4746     0.2409  -1.9700 0.0488     -0.9467    -0.0024\n",
       "region_region_3                0.2860     0.2733   1.0465 0.2953     -0.2497     0.8217\n",
       "region_region_30               0.1512     0.2395   0.6311 0.5280     -0.3183     0.6206\n",
       "region_region_31              -0.2304     0.2030  -1.1351 0.2563     -0.6282     0.1674\n",
       "region_region_32              -0.4985     0.2495  -1.9978 0.0457     -0.9876    -0.0094\n",
       "region_region_33              -0.4052     0.3820  -1.0607 0.2888     -1.1539     0.3435\n",
       "region_region_34              -0.9665     0.4579  -2.1107 0.0348     -1.8639    -0.0690\n",
       "region_region_4                0.6563     0.1867   3.5163 0.0004      0.2905     1.0222\n",
       "region_region_5               -0.3840     0.2619  -1.4660 0.1426     -0.8973     0.1294\n",
       "region_region_6               -0.4842     0.2683  -1.8045 0.0712     -1.0101     0.0417\n",
       "region_region_7                0.4076     0.1767   2.3068 0.0211      0.0613     0.7539\n",
       "region_region_8               -0.1974     0.2409  -0.8194 0.4126     -0.6696     0.2748\n",
       "region_region_9               -1.1565     0.4304  -2.6869 0.0072     -2.0000    -0.3129\n",
       "education_BelowSecondary      -0.2308     0.1548  -1.4904 0.1361     -0.5342     0.0727\n",
       "education_Masters              0.1710     0.0452   3.7848 0.0002      0.0824     0.2595\n",
       "education_NotSpecified        -0.4681     0.1148  -4.0796 0.0000     -0.6930    -0.2432\n",
       "gender_m                       0.0335     0.0419   0.7999 0.4238     -0.0486     0.1157\n",
       "recruitment_channel_referred  -0.2175     0.1135  -1.9161 0.0554     -0.4399     0.0050\n",
       "recruitment_channel_sourcing  -0.0146     0.0375  -0.3884 0.6978     -0.0880     0.0589\n",
       "no_of_trainings_10           -19.3079 34257.2130  -0.0006 0.9996 -67162.2115 67123.5958\n",
       "no_of_trainings_2             -0.1735     0.0547  -3.1703 0.0015     -0.2808    -0.0662\n",
       "no_of_trainings_3             -0.2499     0.1144  -2.1849 0.0289     -0.4740    -0.0257\n",
       "no_of_trainings_4             -0.4505     0.2385  -1.8892 0.0589     -0.9180     0.0169\n",
       "no_of_trainings_5             -0.7357     0.6226  -1.1817 0.2373     -1.9560     0.4846\n",
       "no_of_trainings_6             -0.1800     0.7552  -0.2384 0.8116     -1.6602     1.3002\n",
       "no_of_trainings_7            -20.8381 20250.2288  -0.0010 0.9992 -39710.5572 39668.8810\n",
       "no_of_trainings_8            -20.5081 33101.9511  -0.0006 0.9995 -64899.1399 64858.1238\n",
       "no_of_trainings_9            -20.8730 34065.7905  -0.0006 0.9995 -66788.5955 66746.8495\n",
       "previous_year_rating_1        -1.4360     0.1409 -10.1929 0.0000     -1.7121    -1.1598\n",
       "previous_year_rating_2        -0.3751     0.1123  -3.3412 0.0008     -0.5952    -0.1551\n",
       "previous_year_rating_3         0.0137     0.0794   0.1731 0.8626     -0.1420     0.1694\n",
       "previous_year_rating_4        -0.2909     0.0850  -3.4227 0.0006     -0.4575    -0.1243\n",
       "previous_year_rating_5         0.3264     0.0789   4.1385 0.0000      0.1718     0.4810\n",
       "KPIs_met >80%_1                1.8802     0.0445  42.2391 0.0000      1.7930     1.9674\n",
       "awards_won_1                   1.5055     0.0799  18.8525 0.0000      1.3490     1.6620\n",
       "age                           -0.2402     0.0288  -8.3500 0.0000     -0.2966    -0.1838\n",
       "length_of_service              0.1327     0.0260   5.1134 0.0000      0.0819     0.1836\n",
       "avg_training_score             4.0956     0.0687  59.5864 0.0000      3.9609     4.2303\n",
       "=======================================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the variables that are less significant (i.e p value>0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data2 = x_data.drop(['region_region_10','region_region_11','region_region_12','region_region_13',\n",
    "                      'region_region_14','region_region_15','region_region_16','region_region_21',\n",
    "                      'region_region_18','region_region_19','region_region_20','region_region_2',\n",
    "                      'region_region_24','region_region_26','region_region_27','region_region_3',\n",
    "                      'region_region_30','region_region_31','region_region_33','region_region_5',\n",
    "                       'region_region_6','region_region_8','education_BelowSecondary','gender_m',\n",
    "                      'recruitment_channel_sourcing','no_of_trainings_10','no_of_trainings_5',\n",
    "                      'no_of_trainings_6','no_of_trainings_7','no_of_trainings_8','no_of_trainings_9',\n",
    "                      'previous_year_rating_3'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "logm2 = sm.GLM(y_data,(sm.add_constant(x_data2)), family = sm.families.Binomial())\n",
    "model2 = logm2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32917418210354643"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>               <td>GLM</td>            <td>AIC:</td>        <td>21484.2258</td> \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>Link Function:</td>          <td>logit</td>           <td>BIC:</td>       <td>-576246.3726</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>    <td>is_promoted</td>   <td>Log-Likelihood:</td>    <td>-10707.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2019-04-07 12:50</td>    <td>LL-Null:</td>        <td>-15961.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>54808</td>         <td>Deviance:</td>       <td>21414.</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>34</td>         <td>Pearson chi2:</td>    <td>4.39e+04</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>54773</td>          <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "        <td>Method:</td>             <td>IRLS</td>              <td></td>               <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                 <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>     <th>P>|z|</th>  <th>[0.025</th>   <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                        <td>-10.3998</td>  <td>0.1451</td>  <td>-71.6504</td> <td>0.0000</td> <td>-10.6843</td> <td>-10.1153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Finance</th>            <td>7.1026</td>   <td>0.1598</td>   <td>44.4489</td> <td>0.0000</td>  <td>6.7894</td>   <td>7.4158</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_HR</th>                 <td>9.9932</td>   <td>0.2107</td>   <td>47.4235</td> <td>0.0000</td>  <td>9.5801</td>   <td>10.4062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Legal</th>              <td>6.8917</td>   <td>0.2118</td>   <td>32.5459</td> <td>0.0000</td>  <td>6.4766</td>   <td>7.3067</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Operations</th>         <td>7.2777</td>   <td>0.1406</td>   <td>51.7480</td> <td>0.0000</td>  <td>7.0020</td>   <td>7.5533</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Procurement</th>        <td>4.4225</td>   <td>0.1044</td>   <td>42.3611</td> <td>0.0000</td>  <td>4.2179</td>   <td>4.6271</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_RandD</th>              <td>-0.5375</td>  <td>0.1475</td>   <td>-3.6430</td> <td>0.0003</td>  <td>-0.8266</td>  <td>-0.2483</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_SalesMarketing</th>     <td>10.4955</td>  <td>0.1879</td>   <td>55.8661</td> <td>0.0000</td>  <td>10.1273</td>  <td>10.8637</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Technology</th>         <td>1.7638</td>   <td>0.0751</td>   <td>23.4771</td> <td>0.0000</td>  <td>1.6166</td>   <td>1.9110</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_17</th>              <td>0.5223</td>   <td>0.1304</td>   <td>4.0046</td>  <td>0.0001</td>  <td>0.2667</td>   <td>0.7779</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_22</th>              <td>0.4693</td>   <td>0.0542</td>   <td>8.6632</td>  <td>0.0000</td>  <td>0.3631</td>   <td>0.5754</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_23</th>              <td>0.4483</td>   <td>0.1128</td>   <td>3.9758</td>  <td>0.0001</td>  <td>0.2273</td>   <td>0.6693</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_25</th>              <td>0.5344</td>   <td>0.1296</td>   <td>4.1236</td>  <td>0.0000</td>  <td>0.2804</td>   <td>0.7885</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_28</th>              <td>0.3711</td>   <td>0.1092</td>   <td>3.3966</td>  <td>0.0007</td>  <td>0.1569</td>   <td>0.5852</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_29</th>              <td>-0.4587</td>  <td>0.1756</td>   <td>-2.6127</td> <td>0.0090</td>  <td>-0.8028</td>  <td>-0.1146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_32</th>              <td>-0.4882</td>  <td>0.1868</td>   <td>-2.6141</td> <td>0.0089</td>  <td>-0.8542</td>  <td>-0.1222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_34</th>              <td>-0.9413</td>  <td>0.4272</td>   <td>-2.2035</td> <td>0.0276</td>  <td>-1.7785</td>  <td>-0.1040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_4</th>               <td>0.6480</td>   <td>0.0872</td>   <td>7.4342</td>  <td>0.0000</td>  <td>0.4771</td>   <td>0.8188</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_7</th>               <td>0.3913</td>   <td>0.0613</td>   <td>6.3843</td>  <td>0.0000</td>  <td>0.2712</td>   <td>0.5115</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_9</th>               <td>-1.1324</td>  <td>0.3981</td>   <td>-2.8445</td> <td>0.0044</td>  <td>-1.9127</td>  <td>-0.3522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>education_Masters</th>             <td>0.1752</td>   <td>0.0446</td>   <td>3.9271</td>  <td>0.0001</td>  <td>0.0878</td>   <td>0.2627</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>education_NotSpecified</th>        <td>-0.3980</td>  <td>0.1139</td>   <td>-3.4932</td> <td>0.0005</td>  <td>-0.6213</td>  <td>-0.1747</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recruitment_channel_referred</th>  <td>-0.1210</td>  <td>0.1109</td>   <td>-1.0912</td> <td>0.2752</td>  <td>-0.3384</td>  <td>0.0963</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>no_of_trainings_2</th>             <td>-0.1515</td>  <td>0.0544</td>   <td>-2.7839</td> <td>0.0054</td>  <td>-0.2582</td>  <td>-0.0448</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>no_of_trainings_3</th>             <td>-0.2234</td>  <td>0.1142</td>   <td>-1.9561</td> <td>0.0505</td>  <td>-0.4473</td>  <td>0.0004</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>no_of_trainings_4</th>             <td>-0.4211</td>  <td>0.2388</td>   <td>-1.7633</td> <td>0.0779</td>  <td>-0.8893</td>  <td>0.0470</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>previous_year_rating_1</th>        <td>-1.4423</td>  <td>0.1247</td>  <td>-11.5687</td> <td>0.0000</td>  <td>-1.6866</td>  <td>-1.1979</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>previous_year_rating_2</th>        <td>-0.3747</td>  <td>0.0910</td>   <td>-4.1160</td> <td>0.0000</td>  <td>-0.5531</td>  <td>-0.1963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>previous_year_rating_4</th>        <td>-0.2938</td>  <td>0.0544</td>   <td>-5.3962</td> <td>0.0000</td>  <td>-0.4005</td>  <td>-0.1871</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>previous_year_rating_5</th>        <td>0.3172</td>   <td>0.0436</td>   <td>7.2682</td>  <td>0.0000</td>  <td>0.2316</td>   <td>0.4027</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>KPIs_met >80%_1</th>               <td>1.8862</td>   <td>0.0444</td>   <td>42.4910</td> <td>0.0000</td>  <td>1.7992</td>   <td>1.9732</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>awards_won_1</th>                  <td>1.5008</td>   <td>0.0797</td>   <td>18.8222</td> <td>0.0000</td>  <td>1.3445</td>   <td>1.6571</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                           <td>-0.2038</td>  <td>0.0277</td>   <td>-7.3643</td> <td>0.0000</td>  <td>-0.2580</td>  <td>-0.1495</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>length_of_service</th>             <td>0.1353</td>   <td>0.0256</td>   <td>5.2945</td>  <td>0.0000</td>  <td>0.0852</td>   <td>0.1855</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_training_score</th>            <td>4.1054</td>   <td>0.0686</td>   <td>59.8491</td> <td>0.0000</td>  <td>3.9709</td>   <td>4.2398</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                       Results: Generalized linear model\n",
       "================================================================================\n",
       "Model:                   GLM                   AIC:                 21484.2258  \n",
       "Link Function:           logit                 BIC:                 -576246.3726\n",
       "Dependent Variable:      is_promoted           Log-Likelihood:      -10707.     \n",
       "Date:                    2019-04-07 12:50      LL-Null:             -15961.     \n",
       "No. Observations:        54808                 Deviance:            21414.      \n",
       "Df Model:                34                    Pearson chi2:        4.39e+04    \n",
       "Df Residuals:            54773                 Scale:               1.0000      \n",
       "Method:                  IRLS                                                   \n",
       "--------------------------------------------------------------------------------\n",
       "                              Coef.   Std.Err.    z     P>|z|   [0.025   0.975] \n",
       "--------------------------------------------------------------------------------\n",
       "const                        -10.3998   0.1451 -71.6504 0.0000 -10.6843 -10.1153\n",
       "department_Finance             7.1026   0.1598  44.4489 0.0000   6.7894   7.4158\n",
       "department_HR                  9.9932   0.2107  47.4235 0.0000   9.5801  10.4062\n",
       "department_Legal               6.8917   0.2118  32.5459 0.0000   6.4766   7.3067\n",
       "department_Operations          7.2777   0.1406  51.7480 0.0000   7.0020   7.5533\n",
       "department_Procurement         4.4225   0.1044  42.3611 0.0000   4.2179   4.6271\n",
       "department_RandD              -0.5375   0.1475  -3.6430 0.0003  -0.8266  -0.2483\n",
       "department_SalesMarketing     10.4955   0.1879  55.8661 0.0000  10.1273  10.8637\n",
       "department_Technology          1.7638   0.0751  23.4771 0.0000   1.6166   1.9110\n",
       "region_region_17               0.5223   0.1304   4.0046 0.0001   0.2667   0.7779\n",
       "region_region_22               0.4693   0.0542   8.6632 0.0000   0.3631   0.5754\n",
       "region_region_23               0.4483   0.1128   3.9758 0.0001   0.2273   0.6693\n",
       "region_region_25               0.5344   0.1296   4.1236 0.0000   0.2804   0.7885\n",
       "region_region_28               0.3711   0.1092   3.3966 0.0007   0.1569   0.5852\n",
       "region_region_29              -0.4587   0.1756  -2.6127 0.0090  -0.8028  -0.1146\n",
       "region_region_32              -0.4882   0.1868  -2.6141 0.0089  -0.8542  -0.1222\n",
       "region_region_34              -0.9413   0.4272  -2.2035 0.0276  -1.7785  -0.1040\n",
       "region_region_4                0.6480   0.0872   7.4342 0.0000   0.4771   0.8188\n",
       "region_region_7                0.3913   0.0613   6.3843 0.0000   0.2712   0.5115\n",
       "region_region_9               -1.1324   0.3981  -2.8445 0.0044  -1.9127  -0.3522\n",
       "education_Masters              0.1752   0.0446   3.9271 0.0001   0.0878   0.2627\n",
       "education_NotSpecified        -0.3980   0.1139  -3.4932 0.0005  -0.6213  -0.1747\n",
       "recruitment_channel_referred  -0.1210   0.1109  -1.0912 0.2752  -0.3384   0.0963\n",
       "no_of_trainings_2             -0.1515   0.0544  -2.7839 0.0054  -0.2582  -0.0448\n",
       "no_of_trainings_3             -0.2234   0.1142  -1.9561 0.0505  -0.4473   0.0004\n",
       "no_of_trainings_4             -0.4211   0.2388  -1.7633 0.0779  -0.8893   0.0470\n",
       "previous_year_rating_1        -1.4423   0.1247 -11.5687 0.0000  -1.6866  -1.1979\n",
       "previous_year_rating_2        -0.3747   0.0910  -4.1160 0.0000  -0.5531  -0.1963\n",
       "previous_year_rating_4        -0.2938   0.0544  -5.3962 0.0000  -0.4005  -0.1871\n",
       "previous_year_rating_5         0.3172   0.0436   7.2682 0.0000   0.2316   0.4027\n",
       "KPIs_met >80%_1                1.8862   0.0444  42.4910 0.0000   1.7992   1.9732\n",
       "awards_won_1                   1.5008   0.0797  18.8222 0.0000   1.3445   1.6571\n",
       "age                           -0.2038   0.0277  -7.3643 0.0000  -0.2580  -0.1495\n",
       "length_of_service              0.1353   0.0256   5.2945 0.0000   0.0852   0.1855\n",
       "avg_training_score             4.1054   0.0686  59.8491 0.0000   3.9709   4.2398\n",
       "================================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data2 = x_data2.drop(['no_of_trainings_3','no_of_trainings_4','recruitment_channel_referred'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "logm3 = sm.GLM(y_data,(sm.add_constant(x_data2)), family = sm.families.Binomial())\n",
    "model3 = logm3.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32891386568423187"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2(model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>               <td>GLM</td>            <td>AIC:</td>        <td>21486.5357</td> \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>Link Function:</td>          <td>logit</td>           <td>BIC:</td>       <td>-576270.7975</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>    <td>is_promoted</td>   <td>Log-Likelihood:</td>    <td>-10711.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2019-04-07 12:50</td>    <td>LL-Null:</td>        <td>-15961.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>54808</td>         <td>Deviance:</td>       <td>21423.</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>31</td>         <td>Pearson chi2:</td>    <td>4.37e+04</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>54776</td>          <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "        <td>Method:</td>             <td>IRLS</td>              <td></td>               <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>     <th>P>|z|</th>  <th>[0.025</th>   <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                     <td>-10.4167</td>  <td>0.1450</td>  <td>-71.8401</td> <td>0.0000</td> <td>-10.7009</td> <td>-10.1325</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Finance</th>         <td>7.1047</td>   <td>0.1598</td>   <td>44.4727</td> <td>0.0000</td>  <td>6.7916</td>   <td>7.4178</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_HR</th>              <td>10.0017</td>  <td>0.2105</td>   <td>47.5131</td> <td>0.0000</td>  <td>9.5891</td>   <td>10.4143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Legal</th>           <td>6.9002</td>   <td>0.2117</td>   <td>32.5932</td> <td>0.0000</td>  <td>6.4853</td>   <td>7.3152</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Operations</th>      <td>7.2822</td>   <td>0.1405</td>   <td>51.8154</td> <td>0.0000</td>  <td>7.0068</td>   <td>7.5577</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Procurement</th>     <td>4.4219</td>   <td>0.1044</td>   <td>42.3759</td> <td>0.0000</td>  <td>4.2174</td>   <td>4.6265</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_RandD</th>           <td>-0.5427</td>  <td>0.1476</td>   <td>-3.6764</td> <td>0.0002</td>  <td>-0.8321</td>  <td>-0.2534</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_SalesMarketing</th>  <td>10.4972</td>  <td>0.1877</td>   <td>55.9111</td> <td>0.0000</td>  <td>10.1292</td>  <td>10.8652</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Technology</th>      <td>1.7585</td>   <td>0.0749</td>   <td>23.4718</td> <td>0.0000</td>  <td>1.6117</td>   <td>1.9054</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_17</th>           <td>0.5305</td>   <td>0.1304</td>   <td>4.0690</td>  <td>0.0000</td>  <td>0.2750</td>   <td>0.7860</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_22</th>           <td>0.4527</td>   <td>0.0537</td>   <td>8.4240</td>  <td>0.0000</td>  <td>0.3473</td>   <td>0.5580</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_23</th>           <td>0.4494</td>   <td>0.1127</td>   <td>3.9859</td>  <td>0.0001</td>  <td>0.2284</td>   <td>0.6704</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_25</th>           <td>0.5382</td>   <td>0.1296</td>   <td>4.1530</td>  <td>0.0000</td>  <td>0.2842</td>   <td>0.7922</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_28</th>           <td>0.3722</td>   <td>0.1092</td>   <td>3.4094</td>  <td>0.0007</td>  <td>0.1582</td>   <td>0.5862</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_29</th>           <td>-0.4496</td>  <td>0.1755</td>   <td>-2.5621</td> <td>0.0104</td>  <td>-0.7935</td>  <td>-0.1057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_32</th>           <td>-0.4933</td>  <td>0.1870</td>   <td>-2.6382</td> <td>0.0083</td>  <td>-0.8598</td>  <td>-0.1268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_34</th>           <td>-0.9401</td>  <td>0.4272</td>   <td>-2.2005</td> <td>0.0278</td>  <td>-1.7775</td>  <td>-0.1028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_4</th>            <td>0.6516</td>   <td>0.0871</td>   <td>7.4785</td>  <td>0.0000</td>  <td>0.4808</td>   <td>0.8223</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_7</th>            <td>0.3925</td>   <td>0.0613</td>   <td>6.4064</td>  <td>0.0000</td>  <td>0.2725</td>   <td>0.5126</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_9</th>            <td>-1.1318</td>  <td>0.3980</td>   <td>-2.8435</td> <td>0.0045</td>  <td>-1.9119</td>  <td>-0.3517</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>education_Masters</th>          <td>0.1787</td>   <td>0.0446</td>   <td>4.0075</td>  <td>0.0001</td>  <td>0.0913</td>   <td>0.2661</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>education_NotSpecified</th>     <td>-0.3859</td>  <td>0.1138</td>   <td>-3.3925</td> <td>0.0007</td>  <td>-0.6089</td>  <td>-0.1630</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>no_of_trainings_2</th>          <td>-0.1381</td>  <td>0.0542</td>   <td>-2.5477</td> <td>0.0108</td>  <td>-0.2443</td>  <td>-0.0319</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>previous_year_rating_1</th>     <td>-1.4424</td>  <td>0.1247</td>  <td>-11.5708</td> <td>0.0000</td>  <td>-1.6867</td>  <td>-1.1981</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>previous_year_rating_2</th>     <td>-0.3704</td>  <td>0.0910</td>   <td>-4.0697</td> <td>0.0000</td>  <td>-0.5487</td>  <td>-0.1920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>previous_year_rating_4</th>     <td>-0.2897</td>  <td>0.0544</td>   <td>-5.3240</td> <td>0.0000</td>  <td>-0.3963</td>  <td>-0.1830</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>previous_year_rating_5</th>     <td>0.3194</td>   <td>0.0436</td>   <td>7.3272</td>  <td>0.0000</td>  <td>0.2339</td>   <td>0.4048</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>KPIs_met >80%_1</th>            <td>1.8870</td>   <td>0.0444</td>   <td>42.5238</td> <td>0.0000</td>  <td>1.8000</td>   <td>1.9740</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>awards_won_1</th>               <td>1.5023</td>   <td>0.0797</td>   <td>18.8431</td> <td>0.0000</td>  <td>1.3461</td>   <td>1.6586</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                        <td>-0.2011</td>  <td>0.0277</td>   <td>-7.2732</td> <td>0.0000</td>  <td>-0.2553</td>  <td>-0.1469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>length_of_service</th>          <td>0.1353</td>   <td>0.0256</td>   <td>5.2924</td>  <td>0.0000</td>  <td>0.0852</td>   <td>0.1854</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_training_score</th>         <td>4.1046</td>   <td>0.0686</td>   <td>59.8610</td> <td>0.0000</td>  <td>3.9702</td>   <td>4.2390</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                      Results: Generalized linear model\n",
       "=============================================================================\n",
       "Model:                  GLM                  AIC:                21486.5357  \n",
       "Link Function:          logit                BIC:                -576270.7975\n",
       "Dependent Variable:     is_promoted          Log-Likelihood:     -10711.     \n",
       "Date:                   2019-04-07 12:50     LL-Null:            -15961.     \n",
       "No. Observations:       54808                Deviance:           21423.      \n",
       "Df Model:               31                   Pearson chi2:       4.37e+04    \n",
       "Df Residuals:           54776                Scale:              1.0000      \n",
       "Method:                 IRLS                                                 \n",
       "-----------------------------------------------------------------------------\n",
       "                           Coef.   Std.Err.    z     P>|z|   [0.025   0.975] \n",
       "-----------------------------------------------------------------------------\n",
       "const                     -10.4167   0.1450 -71.8401 0.0000 -10.7009 -10.1325\n",
       "department_Finance          7.1047   0.1598  44.4727 0.0000   6.7916   7.4178\n",
       "department_HR              10.0017   0.2105  47.5131 0.0000   9.5891  10.4143\n",
       "department_Legal            6.9002   0.2117  32.5932 0.0000   6.4853   7.3152\n",
       "department_Operations       7.2822   0.1405  51.8154 0.0000   7.0068   7.5577\n",
       "department_Procurement      4.4219   0.1044  42.3759 0.0000   4.2174   4.6265\n",
       "department_RandD           -0.5427   0.1476  -3.6764 0.0002  -0.8321  -0.2534\n",
       "department_SalesMarketing  10.4972   0.1877  55.9111 0.0000  10.1292  10.8652\n",
       "department_Technology       1.7585   0.0749  23.4718 0.0000   1.6117   1.9054\n",
       "region_region_17            0.5305   0.1304   4.0690 0.0000   0.2750   0.7860\n",
       "region_region_22            0.4527   0.0537   8.4240 0.0000   0.3473   0.5580\n",
       "region_region_23            0.4494   0.1127   3.9859 0.0001   0.2284   0.6704\n",
       "region_region_25            0.5382   0.1296   4.1530 0.0000   0.2842   0.7922\n",
       "region_region_28            0.3722   0.1092   3.4094 0.0007   0.1582   0.5862\n",
       "region_region_29           -0.4496   0.1755  -2.5621 0.0104  -0.7935  -0.1057\n",
       "region_region_32           -0.4933   0.1870  -2.6382 0.0083  -0.8598  -0.1268\n",
       "region_region_34           -0.9401   0.4272  -2.2005 0.0278  -1.7775  -0.1028\n",
       "region_region_4             0.6516   0.0871   7.4785 0.0000   0.4808   0.8223\n",
       "region_region_7             0.3925   0.0613   6.4064 0.0000   0.2725   0.5126\n",
       "region_region_9            -1.1318   0.3980  -2.8435 0.0045  -1.9119  -0.3517\n",
       "education_Masters           0.1787   0.0446   4.0075 0.0001   0.0913   0.2661\n",
       "education_NotSpecified     -0.3859   0.1138  -3.3925 0.0007  -0.6089  -0.1630\n",
       "no_of_trainings_2          -0.1381   0.0542  -2.5477 0.0108  -0.2443  -0.0319\n",
       "previous_year_rating_1     -1.4424   0.1247 -11.5708 0.0000  -1.6867  -1.1981\n",
       "previous_year_rating_2     -0.3704   0.0910  -4.0697 0.0000  -0.5487  -0.1920\n",
       "previous_year_rating_4     -0.2897   0.0544  -5.3240 0.0000  -0.3963  -0.1830\n",
       "previous_year_rating_5      0.3194   0.0436   7.3272 0.0000   0.2339   0.4048\n",
       "KPIs_met >80%_1             1.8870   0.0444  42.5238 0.0000   1.8000   1.9740\n",
       "awards_won_1                1.5023   0.0797  18.8431 0.0000   1.3461   1.6586\n",
       "age                        -0.2011   0.0277  -7.2732 0.0000  -0.2553  -0.1469\n",
       "length_of_service           0.1353   0.0256   5.2924 0.0000   0.0852   0.1854\n",
       "avg_training_score          4.1046   0.0686  59.8610 0.0000   3.9702   4.2390\n",
       "=============================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection Using RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True False  True  True False False False False\n",
      " False  True  True  True False False  True False False False  True False\n",
      " False False  True  True False False  True]\n",
      "[ 1  1  1  1  1  2  1  1  6  8  7  5  9  1  1  1  3 10  1 15 11 14  1 12\n",
      " 13  4  1  1 16 17  1]\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "rfe = RFE(logreg, 15)             # running RFE with 20 variables as output\n",
    "rfe = rfe.fit(x_data2,y_data)\n",
    "print(rfe.support_)           # Printing the boolean results\n",
    "print(rfe.ranking_)           # Printing the ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['department_Finance', 'department_HR', 'department_Legal',\n",
       "       'department_Operations', 'department_Procurement', 'department_RandD',\n",
       "       'department_SalesMarketing', 'department_Technology',\n",
       "       'region_region_17', 'region_region_22', 'region_region_23',\n",
       "       'region_region_25', 'region_region_28', 'region_region_29',\n",
       "       'region_region_32', 'region_region_34', 'region_region_4',\n",
       "       'region_region_7', 'region_region_9', 'education_Masters',\n",
       "       'education_NotSpecified', 'no_of_trainings_2', 'previous_year_rating_1',\n",
       "       'previous_year_rating_2', 'previous_year_rating_4',\n",
       "       'previous_year_rating_5', 'KPIs_met >80%_1', 'awards_won_1', 'age',\n",
       "       'length_of_service', 'avg_training_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data3 = x_data2[['department_Finance', 'department_HR', 'department_Legal',\n",
    "       'department_Operations', 'department_Procurement','department_SalesMarketing', 'department_Technology',\n",
    "                  'region_region_29','region_region_32', 'region_region_34','region_region_9',\n",
    "                  'previous_year_rating_1','KPIs_met >80%_1', 'awards_won_1','avg_training_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "logm4 = sm.GLM(y_data,(sm.add_constant(x_data3)), family = sm.families.Binomial())\n",
    "model4 = logm4.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3153424792581139"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2(model4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>               <td>GLM</td>            <td>AIC:</td>        <td>21887.7640</td> \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>Link Function:</td>          <td>logit</td>           <td>BIC:</td>       <td>-576012.1546</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>    <td>is_promoted</td>   <td>Log-Likelihood:</td>    <td>-10928.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2019-04-07 12:50</td>    <td>LL-Null:</td>        <td>-15961.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>54808</td>         <td>Deviance:</td>       <td>21856.</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>15</td>         <td>Pearson chi2:</td>    <td>4.52e+04</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>54792</td>          <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "        <td>Method:</td>             <td>IRLS</td>              <td></td>               <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>     <th>P>|z|</th>  <th>[0.025</th>   <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                     <td>-10.3224</td>  <td>0.1392</td>  <td>-74.1444</td> <td>0.0000</td> <td>-10.5953</td> <td>-10.0496</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Finance</th>         <td>7.2525</td>   <td>0.1574</td>   <td>46.0767</td> <td>0.0000</td>  <td>6.9440</td>   <td>7.5610</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_HR</th>              <td>10.1901</td>  <td>0.2077</td>   <td>49.0665</td> <td>0.0000</td>  <td>9.7830</td>   <td>10.5971</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Legal</th>           <td>7.0167</td>   <td>0.2091</td>   <td>33.5593</td> <td>0.0000</td>  <td>6.6069</td>   <td>7.4265</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Operations</th>      <td>7.3935</td>   <td>0.1375</td>   <td>53.7740</td> <td>0.0000</td>  <td>7.1240</td>   <td>7.6630</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Procurement</th>     <td>4.4651</td>   <td>0.1001</td>   <td>44.6063</td> <td>0.0000</td>  <td>4.2689</td>   <td>4.6613</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_SalesMarketing</th>  <td>10.6130</td>  <td>0.1853</td>   <td>57.2623</td> <td>0.0000</td>  <td>10.2498</td>  <td>10.9763</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>department_Technology</th>      <td>1.7225</td>   <td>0.0703</td>   <td>24.4993</td> <td>0.0000</td>  <td>1.5847</td>   <td>1.8603</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_29</th>           <td>-0.6367</td>  <td>0.1744</td>   <td>-3.6504</td> <td>0.0003</td>  <td>-0.9786</td>  <td>-0.2949</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_32</th>           <td>-0.6639</td>  <td>0.1854</td>   <td>-3.5807</td> <td>0.0003</td>  <td>-1.0272</td>  <td>-0.3005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_34</th>           <td>-1.0677</td>  <td>0.4238</td>   <td>-2.5192</td> <td>0.0118</td>  <td>-1.8985</td>  <td>-0.2370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_region_9</th>            <td>-1.2893</td>  <td>0.3953</td>   <td>-3.2619</td> <td>0.0011</td>  <td>-2.0639</td>  <td>-0.5146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>previous_year_rating_1</th>     <td>-1.4823</td>  <td>0.1224</td>  <td>-12.1083</td> <td>0.0000</td>  <td>-1.7223</td>  <td>-1.2424</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>KPIs_met >80%_1</th>            <td>1.9737</td>   <td>0.0422</td>   <td>46.7559</td> <td>0.0000</td>  <td>1.8910</td>   <td>2.0565</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>awards_won_1</th>               <td>1.4230</td>   <td>0.0782</td>   <td>18.2034</td> <td>0.0000</td>  <td>1.2698</td>   <td>1.5762</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_training_score</th>         <td>4.1588</td>   <td>0.0681</td>   <td>61.0887</td> <td>0.0000</td>  <td>4.0254</td>   <td>4.2923</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                      Results: Generalized linear model\n",
       "=============================================================================\n",
       "Model:                  GLM                  AIC:                21887.7640  \n",
       "Link Function:          logit                BIC:                -576012.1546\n",
       "Dependent Variable:     is_promoted          Log-Likelihood:     -10928.     \n",
       "Date:                   2019-04-07 12:50     LL-Null:            -15961.     \n",
       "No. Observations:       54808                Deviance:           21856.      \n",
       "Df Model:               15                   Pearson chi2:       4.52e+04    \n",
       "Df Residuals:           54792                Scale:              1.0000      \n",
       "Method:                 IRLS                                                 \n",
       "-----------------------------------------------------------------------------\n",
       "                           Coef.   Std.Err.    z     P>|z|   [0.025   0.975] \n",
       "-----------------------------------------------------------------------------\n",
       "const                     -10.3224   0.1392 -74.1444 0.0000 -10.5953 -10.0496\n",
       "department_Finance          7.2525   0.1574  46.0767 0.0000   6.9440   7.5610\n",
       "department_HR              10.1901   0.2077  49.0665 0.0000   9.7830  10.5971\n",
       "department_Legal            7.0167   0.2091  33.5593 0.0000   6.6069   7.4265\n",
       "department_Operations       7.3935   0.1375  53.7740 0.0000   7.1240   7.6630\n",
       "department_Procurement      4.4651   0.1001  44.6063 0.0000   4.2689   4.6613\n",
       "department_SalesMarketing  10.6130   0.1853  57.2623 0.0000  10.2498  10.9763\n",
       "department_Technology       1.7225   0.0703  24.4993 0.0000   1.5847   1.8603\n",
       "region_region_29           -0.6367   0.1744  -3.6504 0.0003  -0.9786  -0.2949\n",
       "region_region_32           -0.6639   0.1854  -3.5807 0.0003  -1.0272  -0.3005\n",
       "region_region_34           -1.0677   0.4238  -2.5192 0.0118  -1.8985  -0.2370\n",
       "region_region_9            -1.2893   0.3953  -3.2619 0.0011  -2.0639  -0.5146\n",
       "previous_year_rating_1     -1.4823   0.1224 -12.1083 0.0000  -1.7223  -1.2424\n",
       "KPIs_met >80%_1             1.9737   0.0422  46.7559 0.0000   1.8910   2.0565\n",
       "awards_won_1                1.4230   0.0782  18.2034 0.0000   1.2698   1.5762\n",
       "avg_training_score          4.1588   0.0681  61.0887 0.0000   4.0254   4.2923\n",
       "=============================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF for calculating vif value\n",
    "def vif_cal(input_data, dependent_col):\n",
    "    vif_df = pd.DataFrame( columns = ['Var', 'Vif'])\n",
    "    x_vars=input_data\n",
    "    xvar_names=x_vars.columns\n",
    "    for i in range(0,xvar_names.shape[0]):\n",
    "        y=x_vars[xvar_names[i]] \n",
    "        x=x_vars[xvar_names.drop(xvar_names[i])]\n",
    "        rsq=sm.OLS(y,x).fit().rsquared  \n",
    "        vif=round(1/(1-rsq),2)\n",
    "        vif_df.loc[i] = [xvar_names[i], vif]\n",
    "    return vif_df.sort_values(by = 'Vif', axis=0, ascending=False, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var</th>\n",
       "      <th>Vif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>avg_training_score</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>region_region_9</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>region_region_29</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>awards_won_1</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>region_region_32</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>region_region_34</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>department_Finance</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>department_HR</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>department_Technology</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>department_Procurement</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>department_SalesMarketing</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>department_Legal</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>department_Operations</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>previous_year_rating_1</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KPIs_met &gt;80%_1</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Var   Vif\n",
       "14         avg_training_score  2.68\n",
       "10            region_region_9  0.40\n",
       "7            region_region_29  0.23\n",
       "13               awards_won_1  0.20\n",
       "8            region_region_32  0.19\n",
       "9            region_region_34  0.12\n",
       "0          department_Finance  0.10\n",
       "1               department_HR  0.06\n",
       "6       department_Technology  0.05\n",
       "4      department_Procurement  0.04\n",
       "5   department_SalesMarketing  0.03\n",
       "2            department_Legal  0.01\n",
       "3       department_Operations  0.01\n",
       "11     previous_year_rating_1  0.01\n",
       "12            KPIs_met >80%_1  0.01"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif_cal(x_data3,y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Variance influence factor is less for all variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the data for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data3, y_data, test_size=0.20, stratify = y_data, random_state = 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_final = LogisticRegression()\n",
    "log_final.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_final.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96     10028\n",
      "           1       0.85      0.22      0.35       934\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10962\n",
      "   macro avg       0.89      0.61      0.66     10962\n",
      "weighted avg       0.92      0.93      0.91     10962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.930122240467068"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9992,   36],\n",
       "       [ 730,  204]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores of the Model\n",
      "Confusion Matrix of the model:\n",
      "[[9992   36]\n",
      " [ 730  204]]\n",
      "-----------------------------------------\n",
      "Accuracy Score: 0.930122240467068\n",
      "-----------------------------------------\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96     10028\n",
      "           1       0.85      0.22      0.35       934\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10962\n",
      "   macro avg       0.89      0.61      0.66     10962\n",
      "weighted avg       0.92      0.93      0.91     10962\n",
      "\n",
      "------------------------------------------\n",
      "f1 score: 0.34752981260647364\n",
      "------------------------------------------\n",
      "ROC AUC score: 0.6074127347068466\n",
      "------------------------------------------\n",
      "\n",
      "Cross Validation using KFold:\n",
      "Accuracy score using KFold cross validation:\n",
      "cross_val_score: 0.3539967373572594\n",
      "cross_val_score: 0.3616438356164383\n",
      "cross_val_score: 0.3557446808510638\n",
      "cross_val_score: 0.3667763157894737\n",
      "cross_val_score: 0.3548117154811715\n",
      "Mean Acuuracy Score: 0.35859465701908133\n"
     ]
    }
   ],
   "source": [
    "model(LogisticRegression(),x_data3,y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores of the Model\n",
      "Confusion Matrix of the model:\n",
      "[[9977   51]\n",
      " [ 701  233]]\n",
      "-----------------------------------------\n",
      "Accuracy Score: 0.9313993796752418\n",
      "-----------------------------------------\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     10028\n",
      "           1       0.82      0.25      0.38       934\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10962\n",
      "   macro avg       0.88      0.62      0.67     10962\n",
      "weighted avg       0.92      0.93      0.91     10962\n",
      "\n",
      "------------------------------------------\n",
      "f1 score: 0.38259441707717573\n",
      "------------------------------------------\n",
      "ROC AUC score: 0.6221894541109305\n",
      "------------------------------------------\n",
      "\n",
      "Cross Validation using KFold:\n",
      "Accuracy score using KFold cross validation:\n",
      "cross_val_score: 0.3981117230527144\n",
      "cross_val_score: 0.39792387543252594\n",
      "cross_val_score: 0.39247751430907607\n",
      "cross_val_score: 0.4106583072100313\n",
      "cross_val_score: 0.38735818476499195\n",
      "Mean Acuuracy Score: 0.39730592095386796\n"
     ]
    }
   ],
   "source": [
    "lr_final= LogisticRegression(C=10000, penalty='l2')\n",
    "model(lr_final,x_data3,y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores of the Model\n",
      "Confusion Matrix of the model:\n",
      "[[7510 2518]\n",
      " [ 154  780]]\n",
      "-----------------------------------------\n",
      "Accuracy Score: 0.7562488596971355\n",
      "-----------------------------------------\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.75      0.85     10028\n",
      "           1       0.24      0.84      0.37       934\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     10962\n",
      "   macro avg       0.61      0.79      0.61     10962\n",
      "weighted avg       0.92      0.76      0.81     10962\n",
      "\n",
      "------------------------------------------\n",
      "f1 score: 0.3686200378071834\n",
      "------------------------------------------\n",
      "ROC AUC score: 0.7920104222096759\n",
      "------------------------------------------\n",
      "\n",
      "Cross Validation using KFold:\n",
      "Accuracy score using KFold cross validation:\n",
      "cross_val_score: 0.37149532710280375\n",
      "cross_val_score: 0.34642945391648133\n",
      "cross_val_score: 0.35637918745545255\n",
      "cross_val_score: 0.3740028155795402\n",
      "cross_val_score: 0.3694874851013111\n",
      "Mean Acuuracy Score: 0.36355885383111775\n"
     ]
    }
   ],
   "source": [
    "lr_final= LogisticRegression(C=10000, penalty='l2',class_weight='balanced')\n",
    "model(lr_final,x_data3,y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0,\n",
      "          class_weight={0: 0.23947368421052628, 1: 0.7605263157894737},\n",
      "          dual=False, fit_intercept=True, intercept_scaling=1,\n",
      "          max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
      "          random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
      "          warm_start=False)\n",
      "0.4145189003436426\n"
     ]
    }
   ],
   "source": [
    "weights = np.linspace(0.05, 0.95, 20)\n",
    "tuned_parameters = {'class_weight':  [{0: x, 1: 1.0-x} for x in weights]}\n",
    "\n",
    "model_lr = GridSearchCV(LogisticRegression(), tuned_parameters, scoring = 'f1', cv=5)\n",
    "model_lr.fit(x_data3, y_data)\n",
    "\n",
    "print(model_lr.best_estimator_)\n",
    "print(model_lr.score(x_data3, y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores of the Model\n",
      "Confusion Matrix of the model:\n",
      "[[9382  646]\n",
      " [ 520  414]]\n",
      "-----------------------------------------\n",
      "Accuracy Score: 0.8936325488049626\n",
      "-----------------------------------------\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94     10028\n",
      "           1       0.39      0.44      0.42       934\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     10962\n",
      "   macro avg       0.67      0.69      0.68     10962\n",
      "weighted avg       0.90      0.89      0.90     10962\n",
      "\n",
      "------------------------------------------\n",
      "f1 score: 0.41524573721163494\n",
      "------------------------------------------\n",
      "ROC AUC score: 0.6894175964686459\n",
      "------------------------------------------\n",
      "\n",
      "Cross Validation using KFold:\n",
      "Accuracy score using KFold cross validation:\n",
      "cross_val_score: 0.4345772319319792\n",
      "cross_val_score: 0.38925494171312724\n",
      "cross_val_score: 0.4129353233830846\n",
      "cross_val_score: 0.47082096933728984\n",
      "cross_val_score: 0.41935483870967744\n",
      "Mean Acuuracy Score: 0.42538866101503164\n"
     ]
    }
   ],
   "source": [
    "lr_final= LogisticRegression(C=10000, penalty='l2',class_weight={0: 0.23, 1: 0.76})\n",
    "model(lr_final,x_data3,y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight={0: 0.28684210526315784, 1: 0.7131578947368422},\n",
      "            criterion='gini', max_depth=None, max_features=None,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "0.5406113537117905\n"
     ]
    }
   ],
   "source": [
    "#Tuning class weight\n",
    "model_dt = GridSearchCV(DecisionTreeClassifier(), tuned_parameters, scoring = 'f1', cv=5)\n",
    "model_dt.fit(x_data3, y_data)\n",
    "\n",
    "print(model_dt.best_estimator_)\n",
    "print(model_dt.score(x_data3, y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=13,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "0.5202312138728324\n"
     ]
    }
   ],
   "source": [
    "#Tuning max depth\n",
    "parameters = {'max_depth': range(1, 40)}\n",
    "model_dt = GridSearchCV(DecisionTreeClassifier(),parameters, scoring = 'f1', cv=5)\n",
    "model_dt.fit(x_data3, y_data)\n",
    "\n",
    "print(model_dt.best_estimator_)\n",
    "print(model_dt.score(x_data3, y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=5, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "0.5063569298383299\n"
     ]
    }
   ],
   "source": [
    "#Tuning min samples\n",
    "parameters = {'min_samples_leaf': range(5, 200, 5)}\n",
    "model_dt = GridSearchCV(DecisionTreeClassifier(),parameters, scoring = 'f1', cv=5)\n",
    "model_dt.fit(x_data3, y_data)\n",
    "\n",
    "print(model_dt.best_estimator_)\n",
    "print(model_dt.score(x_data3, y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=20,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "0.5177680798004988\n"
     ]
    }
   ],
   "source": [
    "#Tuning minimum samples split\n",
    "parameters = {'min_samples_split': range(5, 200, 5)}\n",
    "\n",
    "model_dt = GridSearchCV(DecisionTreeClassifier(),parameters, scoring = 'f1', cv=5)\n",
    "model_dt.fit(x_data3, y_data)\n",
    "\n",
    "print(model_dt.best_estimator_)\n",
    "print(model_dt.score(x_data3, y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores of the Model\n",
      "Confusion Matrix of the model:\n",
      "[[9921  107]\n",
      " [ 578  356]]\n",
      "-----------------------------------------\n",
      "Accuracy Score: 0.9375114030286444\n",
      "-----------------------------------------\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97     10028\n",
      "           1       0.77      0.38      0.51       934\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10962\n",
      "   macro avg       0.86      0.69      0.74     10962\n",
      "weighted avg       0.93      0.94      0.93     10962\n",
      "\n",
      "------------------------------------------\n",
      "f1 score: 0.5096635647816751\n",
      "------------------------------------------\n",
      "ROC AUC score: 0.6852430966313594\n",
      "------------------------------------------\n",
      "\n",
      "Cross Validation using KFold:\n",
      "Accuracy score using KFold cross validation:\n",
      "cross_val_score: 0.5038381018841591\n",
      "cross_val_score: 0.48427672955974843\n",
      "cross_val_score: 0.4851190476190476\n",
      "cross_val_score: 0.5305841924398627\n",
      "cross_val_score: 0.5017921146953405\n",
      "Mean Acuuracy Score: 0.5011220372396317\n"
     ]
    }
   ],
   "source": [
    "tree=DecisionTreeClassifier(max_depth=13, min_samples_split=20,min_samples_leaf=5,class_weight={0: 0.28, 1: 0.72})\n",
    "model(tree,x_data3,y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True,\n",
      "            class_weight={0: 0.28684210526315784, 1: 0.7131578947368422},\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=None, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "0.535338785046729\n"
     ]
    }
   ],
   "source": [
    "#Tuning class weight\n",
    "model_dt = GridSearchCV(RandomForestClassifier(), tuned_parameters, scoring = 'f1', cv=5)\n",
    "model_dt.fit(x_data3, y_data)\n",
    "\n",
    "print(model_dt.best_estimator_)\n",
    "print(model_dt.score(x_data3, y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.5183213279047917\n"
     ]
    }
   ],
   "source": [
    "#Tuning max depth\n",
    "parameters = {'max_depth': range(1, 40)}\n",
    "model_dt = GridSearchCV(RandomForestClassifier(),parameters, scoring = 'f1', cv=5)\n",
    "model_dt.fit(x_data3, y_data)\n",
    "\n",
    "print(model_dt.best_estimator_)\n",
    "print(model_dt.score(x_data3, y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=5, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.5051076536225051\n"
     ]
    }
   ],
   "source": [
    "#Tuning min samples\n",
    "parameters = {'min_samples_leaf': range(5, 200, 5)}\n",
    "model_dt = GridSearchCV(RandomForestClassifier(),parameters, scoring = 'f1', cv=5)\n",
    "model_dt.fit(x_data3, y_data)\n",
    "\n",
    "print(model_dt.best_estimator_)\n",
    "print(model_dt.score(x_data3, y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=55,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.5132688104901655\n"
     ]
    }
   ],
   "source": [
    "#Tuning minimum samples split\n",
    "parameters = {'min_samples_split': range(5, 200, 5)}\n",
    "\n",
    "model_dt = GridSearchCV(RandomForestClassifier(),parameters, scoring = 'f1', cv=5)\n",
    "model_dt.fit(x_data3, y_data)\n",
    "\n",
    "print(model_dt.best_estimator_)\n",
    "print(model_dt.score(x_data3, y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores of the Model\n",
      "Confusion Matrix of the model:\n",
      "[[9949   79]\n",
      " [ 608  326]]\n",
      "-----------------------------------------\n",
      "Accuracy Score: 0.9373289545703338\n",
      "-----------------------------------------\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97     10028\n",
      "           1       0.80      0.35      0.49       934\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10962\n",
      "   macro avg       0.87      0.67      0.73     10962\n",
      "weighted avg       0.93      0.94      0.93     10962\n",
      "\n",
      "------------------------------------------\n",
      "f1 score: 0.4869305451829724\n",
      "------------------------------------------\n",
      "ROC AUC score: 0.6705792304032648\n",
      "------------------------------------------\n",
      "\n",
      "Cross Validation using KFold:\n",
      "Accuracy score using KFold cross validation:\n",
      "cross_val_score: 0.5038167938931297\n",
      "cross_val_score: 0.49340574088440653\n",
      "cross_val_score: 0.4817300521998508\n",
      "cross_val_score: 0.5238095238095238\n",
      "cross_val_score: 0.4968152866242038\n",
      "Mean Acuuracy Score: 0.4999154794822229\n"
     ]
    }
   ],
   "source": [
    "rf=RandomForestClassifier(max_depth=15, min_samples_split=55,min_samples_leaf=5,class_weight={0: 0.28, 1: 0.72})\n",
    "model(rf,x_data3,y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00735885, 0.00489068, 0.00380785, 0.02989189, 0.00904412,\n",
       "       0.06694484, 0.01006541, 0.00271695, 0.00124456, 0.00087116,\n",
       "       0.00127909, 0.02224378, 0.22774642, 0.07810754, 0.53378686])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>department_Finance</th>\n",
       "      <td>0.007359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>department_HR</th>\n",
       "      <td>0.004891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>department_Legal</th>\n",
       "      <td>0.003808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>department_Operations</th>\n",
       "      <td>0.029892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>department_Procurement</th>\n",
       "      <td>0.009044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>department_SalesMarketing</th>\n",
       "      <td>0.066945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>department_Technology</th>\n",
       "      <td>0.010065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_region_29</th>\n",
       "      <td>0.002717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_region_32</th>\n",
       "      <td>0.001245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_region_34</th>\n",
       "      <td>0.000871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_region_9</th>\n",
       "      <td>0.001279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>previous_year_rating_1</th>\n",
       "      <td>0.022244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KPIs_met &gt;80%_1</th>\n",
       "      <td>0.227746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awards_won_1</th>\n",
       "      <td>0.078108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_training_score</th>\n",
       "      <td>0.533787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           weight_value\n",
       "department_Finance             0.007359\n",
       "department_HR                  0.004891\n",
       "department_Legal               0.003808\n",
       "department_Operations          0.029892\n",
       "department_Procurement         0.009044\n",
       "department_SalesMarketing      0.066945\n",
       "department_Technology          0.010065\n",
       "region_region_29               0.002717\n",
       "region_region_32               0.001245\n",
       "region_region_34               0.000871\n",
       "region_region_9                0.001279\n",
       "previous_year_rating_1         0.022244\n",
       "KPIs_met >80%_1                0.227746\n",
       "awards_won_1                   0.078108\n",
       "avg_training_score             0.533787"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(rf.feature_importances_,\n",
    "                                   index = x_data3.columns)\n",
    "feature_importances.columns=['weight_value']\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2f8ce11048>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(16,6))\n",
    "sns.barplot(data=feature_importances,y=feature_importances.index,x=feature_importances['weight_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
